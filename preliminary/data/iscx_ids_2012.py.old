from datetime import datetime
from lxml import etree
import math
import random

__author__ = "Jarrod N. Bakker"


class ISCX2012IDS:

    _BASE_PATH = "/vol/nerg-solar/bakkerjarr/Datasets/ISCXIDS2012" \
                 "/labeled_flows_xml/"
    _RAND_SEED = 99999999999999999
    _SPLIT_RATIO = 0.67

    def __init__(self, fnames):
        """Initialise.

        :param fnames: List of dataset file names.
        """
        self._rand = random
        self._rand.seed(self._RAND_SEED)
        #self._features = ["totalSourceBytes", "totalDestinationBytes",
        #                  "totalSourcePackets",
        #                  "totalDestinationPackets"]
        #self._features = ["totalSourceBytes", "totalSourcePackets"]
        self._features = ["totalSourceBytes", "startDateTime",
                          "stopDateTime"]
        self._transform = True
        self._dataset_files = []
        for f in fnames:
            self._dataset_files.append(self._BASE_PATH + f)
        self._raw_data = []
        self._raw_labels = []
        self._test_data = []
        self._test_labels = []
        self._train_data = []
        self._train_labels = []
        self._num_normal = 0
        self._num_attack = 0

    def prepare_data(self):
        """Prepare data for processing by different classifiers.

        Data must be read, features extracted, and split into training
        and test sets.

        :return: True if successful, False otherwise.
        """
        for fname in self._dataset_files:
            raw_data, raw_labels = self._read_data(fname)
            self._raw_data.extend(raw_data)
            self._raw_labels.extend(raw_labels)
        feat_data = self._select_features(self._raw_data, self._features)
        if not self._transform:
            self._train_data, self._train_labels, self._test_data, \
                self._test_labels = self._split_dataset(feat_data,
                                                        self._raw_labels,
                                                        self._SPLIT_RATIO)
        else:
            #trans_data = self._transform_data_bpp(feat_data)
            trans_data = self._calculate_flow_duration(feat_data)
            self._train_data, self._train_labels, self._test_data, \
                self._test_labels = self._split_dataset(trans_data,
                                                        self._raw_labels,
                                                        self._SPLIT_RATIO)
        return True

    def get_test_data(self):
        """Return the test data and labels.

        :return: The test data and labels in separate lists.
        """
        return self._test_data, self._test_labels

    def get_train_data(self):
        """Return the training data and labels.

        :return: The training data and labels in separate lists.
        """
        return self._train_data, self._train_labels

    def get_num_norm(self):
        """Return the number of flows labeled as 'Normal'

        :return: Number as an integer.
        """
        return self._num_normal

    def get_num_attack(self):
        """Return the number of flows labeled as 'Attack'

        :return: Number as an integer.
        """
        return self._num_attack

    def _read_data(self, fname):
        """Read data from an ISCX dataset XML.

        :param fname: Name of the file to read the data from.
        :return: The data and labels.
        """
        print("Reading data from: {0}".format(fname))
        data_etree = etree.parse(fname)
        raw_data, raw_labels = self._etree_to_dict(data_etree)
        print("Loading complete.")
        return raw_data, raw_labels

    def _etree_to_dict(self, etree):
        """Convert an XML etree into a list of dicts.

        This method only takes care of elements, not attributes!

        :param etree: Etree object to process
        :return: Data as a list of dict.
        """
        root = etree.getroot()
        data = []
        labels = []
        for flow in root:
            flow_data = {}
            for i in range(len(flow)):
                if flow[i].tag != "Tag":
                    flow_data[flow[i].tag] = flow[i].text
                else:
                    if flow[i].text == "Normal":
                        labels.append(TagValue.Normal)
                        self._num_normal += 1
                    else:
                        labels.append(TagValue.Attack)
                        self._num_attack += 1
            data.append(flow_data)
        return data, labels

    def _select_features(self, dataset, features):
        """Select features from the ISCX data.

        :param dataset: Dataset to select features from.
        :param features: A list of features encoded using the
        FlowElement enum.
        :return: The dataset with the selected features.
        """
        print("Selecting features from data...")
        processed_dataset = []
        for flow in dataset:
            new_entry = []
            for f in features:
                new_entry.append(flow[f])
            processed_dataset.append(new_entry)
        return processed_dataset

    def _split_dataset(self, dataset, labels, split_ratio):
        """Split a dataset into training and test sets.

        Separate lists are also created for the labels.

        Taken from http://machinelearningmastery.com/naive-bayes
        -classifier-scratch-python/. Accessed: 31/05/2016

        :param dataset: The dataset to split.
        :param labels: Labels for each dataset element.
        :return: The training and test sets with separate list for
        their labels.
        """
        print("Splitting dataset into training and testing sets...")
        train_size = int(len(dataset) * split_ratio)
        train_set = []
        train_labels = []
        test_set = list(dataset)
        test_labels = list(labels)
        while len(train_set) < train_size:
            i = self._rand.randrange(len(test_set))
            train_set.append(test_set.pop(i))
            train_labels.append(test_labels.pop(i))
        return train_set, train_labels, test_set, test_labels

    def _transform_data_bpp(self, data):
        """Transform the features in data flows to get the bytes per
        packets ratio.

        :param data: The dataset to transform.
        :return: Transformed data.
        """
        print("Transforming data...")
        trans_data = []
        for flow in data:
            new_entry = []
            src_bp_ratio = 0
            try:
                src_bp_ratio = float(flow[0])/float(flow[2])
            except ZeroDivisionError:
                pass
            new_entry.append(src_bp_ratio)
            dst_bp_ratio = 0
            try:
                dst_bp_ratio = float(flow[1])/float(flow[3])
            except ZeroDivisionError:
                pass
            new_entry.append(dst_bp_ratio)
            trans_data.append(new_entry)
        return trans_data

    def _calculate_flow_duration(self, data):
        """The data to calculate the flow duration time for.

        :param data: The data.
        :return: Transformed data.
        """
        print("Transforming data...")
        trans_data = []
        for flow in data:
            new_entry = []
            src_bytes = 0
            try:
                # Remember to include the source bytes
                src_bytes = math.log(float(flow[0]))
            except ValueError:
                pass
            new_entry.append(src_bytes)
            start_dt = datetime.strptime(flow[1], "%Y-%m-%dT%H:%M:%S")
            stop_dt = datetime.strptime(flow[2], "%Y-%m-%dT%H:%M:%S")
            duration = (stop_dt-start_dt).seconds
            new_entry.append(duration)
            trans_data.append(new_entry)
        return trans_data


class TagValue:
    """Enum for the dataset tag labels.
    """
    Normal = 0
    Attack = 1
